{"ast":null,"code":"export default {\n  name: \"NeuralNetworks-c\",\n  data: function data() {\n    return {};\n  },\n  methods: {}\n};","map":{"version":3,"mappings":"AAgFA;EACAA,wBADA;EAEAC;IAAA;EAAA,CAFA;EAGAC;AAHA","names":["name","data","methods"],"sourceRoot":"src/views/Home","sources":["NeuralNetworks.vue"],"sourcesContent":["<template>\n  <v-app class=\"noselect\" id=\"NeuralNetworks-c\">\n    <!-- v-btn block class=\"primary\">1</v-btn> -->\n    <!-- class=\"ma-0 pa-0\" -->\n    <v-container fill-height fluid>\n      <v-layout\n        row\n        wrap\n        justify-center\n        align-xs-start\n        align-sm-start\n        align-md-start\n        align-lg-center\n        align-xl-center\n        style=\"height: 103%\"\n      >\n        <v-flex xs12 sm12 md12 lg6 xl6>\n          <div\n            data-aos=\"fade-zoom-in\"\n            data-aos-easing=\"ease-in\"\n            data-aos-delay=\"200\"\n            data-aos-once=\"true\"\n          >\n            <div id=\"videocontainer\">\n              <!-- <img src=\"../../assets/logo.png\" style=\"border-radius:15px;margin-top:4px\" width=\"100%\" height=\"100%\" /> -->\n              <video\n                controls\n                width=\"100%\"\n                height=\"100%\"\n                playsinline\n                autoplay\n                loop\n                muted\n              >\n                <source\n                  src=\"../../assets/NeuralNetworkSimulation.mp4\"\n                  type=\"video/mp4\"\n                />\n              </video>\n            </div>\n          </div>\n        </v-flex>\n        <v-flex xs12 sm12 md12 lg6 xl6>\n          <div\n            data-aos=\"fade-zoom-in\"\n            data-aos-easing=\"ease-in\"\n            data-aos-delay=\"200\"\n            data-aos-once=\"true\"\n          >\n            <div id=\"text\">\n              <p>\n                Neural networks are capable of learning any pattern,\n                <br />\n                however every data needs pre-processing.\n                <br /><br />\n                For instance, texts (words) are encoded in Chat-GPT as vectors,\n                <br />\n                so called embeddings. Through context-based training the\n                <br />\n                language model can learn the semantic relations by predicting\n                <br />\n                masked contextual words to cluster the related word vectors.\n                <br /><br />\n                In the video is an example for image recognition. Popular\n                techniques\n                <br />\n                in computer vision are convolutional networks, which process\n                image\n                <br />\n                features with convolutional filters.\n              </p>\n            </div>\n          </div>\n        </v-flex>\n      </v-layout>\n    </v-container>\n  </v-app>\n</template>\n\n<script>\nexport default {\n  name: \"NeuralNetworks-c\",\n  data: () => ({}),\n  methods: {},\n};\n</script>\n<style lang=\"scss\" scoped>\n::v-deep .v-application--wrap {\n  min-height: fit-content;\n}\n.noselect {\n  -webkit-touch-callout: none; /* iOS Safari */\n  -webkit-user-select: none; /* Safari */\n  -khtml-user-select: none; /* Konqueror HTML */\n  -moz-user-select: none; /* Old versions of Firefox */\n  -ms-user-select: none; /* Internet Explorer/Edge */\n  user-select: none; /* Non-prefixed version, currently\n                                  supported by Chrome, Edge, Opera and Firefox */\n}\n#NeuralNetworks-c {\n  position: relative;\n  min-width: 100vw;\n  min-height: 100vh;\n  background-color: #151515;\n}\n#videocontainer {\n  padding-left: 5%;\n}\n#text {\n  text-align: left;\n  padding-left: 4%;\n  color: white;\n  font-family: Trebuchet MS, Lucida Grande, Lucida Sans Unicode, Lucida Sans,\n    Tahoma, sans-serif;\n  font-size: 20px;\n  line-height: 160%;\n}\n@media (max-width: 1400px) {\n  #text {\n    font-size: 19px;\n  }\n}\n@media (max-width: 1350px) {\n  #text {\n    font-size: 18px;\n  }\n}\n@media (max-width: 1300px) {\n  #text {\n    font-size: 17px;\n  }\n}\n@media (max-width: 1263px) {\n  #videocontainer {\n    margin-top: -0.5%;\n    padding-left: 0%;\n  }\n  #text {\n    font-size: 20px;\n    padding-left: 2%;\n    padding-right: 2%;\n    padding-top: 15%;\n    padding-bottom: 15%;\n    text-align: center;\n  }\n}\n@media (max-width: 1150px) {\n  #text {\n    padding-top: 7%;\n    margin-bottom: -20px;\n  }\n}\n@media (max-width: 650px) {\n  #NeuralNetworks-c {\n    min-height: 70vh;\n  }\n  #text {\n    font-size: 16px;\n    padding-top: 7%;\n    padding-bottom: 40%;\n  }\n}\n@media (max-width: 530px) {\n  #text {\n    font-size: 12px;\n  }\n}\n@media (max-width: 400px) {\n  #text {\n    font-size: 12px;\n    padding-left: 0%;\n    padding-right: 0%;\n    margin-top: -1%;\n  }\n}\n@media screen and (orientation: landscape) and (max-width: 850px) and (max-height: 450px) {\n  #NeuralNetworks-c {\n    min-height: 80vh;\n  }\n  #text {\n    padding-top: 5%;\n    padding-bottom: 15%;\n    font-size: 18px;\n  }\n}\n</style>\n"]},"metadata":{},"sourceType":"module"}